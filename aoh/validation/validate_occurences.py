import argparse
import os
from contextlib import ExitStack
from functools import partial
from multiprocessing import cpu_count, Pool
from pathlib import Path

import pandas as pd
import yirgacheffe as yg

def validate_occurence(
    gbif_datum: tuple[int, float, float],
    aohs_path: Path,
) -> tuple[int, float, float, bool]:
    taxon_id, lat, lng = gbif_datum

    aoh_files = list(aohs_path.glob(f"**/{taxon_id}*.tif"))
    if len(aoh_files) == 0:
        return (taxon_id, lat, lng, False)

    with ExitStack() as stack:
        rasters = [stack.enter_context(yg.read_raster(x)) for x in aoh_files]
        aoh = rasters[0]
        for raster in rasters [1:]:
            aoh += raster

        pixel_x, pixel_y = raster.pixel_for_latlng(lat, lng)
        value = aoh.read_array(pixel_x, pixel_y, 1, 1)

    return (taxon_id, lat, lng, value > 0.0)


def process_species(
    aohs_path: Path,
    species_occurences: pd.DataFrame,
) -> pd.DataFrame:
    pass

def validate_occurences(
    gbif_data_path: Path,
    aohs_path: Path,
    output_path: Path,
    process_count: int,
) -> None:
    os.makedirs(output_path.parent, exist_ok=True)

    # The input is from the points.csv generated by fetch_gbif_data.py, which has the columns:
    # iucn_taxon_id, gbif_id, decimalLatitude, decimalLongitude, assessment year
    occurences = pd.read_csv(gbif_data_path)
    occurences.drop(columns=['gbif_data', 'year'], inplace=True)
    occurences.sort_values(['iucn_taxon_id', 'decimalLatitude'], inplace=True)
    occurences_per_species = [group for _, group in occurences.groupby('iucn_taxon_id')]
    with Pool(processes=process_count) as pool:
        results_per_species = pool.map(partial(process_species, aohs_path), occurences_per_species)
    results = pd.concat(results_per_species)
    results.to_csv(output_path)

def main() -> None:
    parser = argparse.ArgumentParser(description="Validate map prevalence.")
    parser.add_argument(
        '--gbif_data_path',
        type=Path,
        help="Data containing downloaded GBIF data.",
        required=True,
        dest="gbif_data_path"
    )
    parser.add_argument(
        '--aoh_results',
        type=Path,
        help="Path of all the AoH outputs.",
        required=True,
        dest="aohs_path"
    )
    parser.add_argument(
        "--output",
        type=Path,
        required=True,
        dest="output_path",
        help="CSV of outliers."
    )
    parser.add_argument(
        "-j",
        type=int,
        required=False,
        default=round(cpu_count() / 2),
        dest="processes_count",
        help="Optional number of concurrent threads to use."
    )
    args = parser.parse_args()

    validate_occurences(
        args.gbif_data_path,
        args.aohs_path,
        args.output_path,
        args.process_count,
    )

if __name__ == "__main__":
    main()
